---
title: "p8105_hw2_crd2162"
author: "Caleigh Dwyer"
date: "2023-09-26"
output: github_document
---

```{r load_library}
library(tidyverse)
library(readxl)
```

## Problem 1: Cleaning and merging FiveThiryEight data

In the chunk below, we will clean the data in pols-month.csv. This data comes from 538 and provides information on the number of national politicians who are democratic or republican at any given time. 

There are some values for which `prez_gop` is `2` -- these are months in which Ford became President following Nixon's resignation. In the new `president` variable created as part of our data cleaning, we code these as `gop` (same as values when `prez_gop` is `1`).

```{r pols_cleaned}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("data/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```


In the chunk below, we will clean the data in snp.csv from 538. This contains information related to Standard & Poorâ€™s stock market index.

```{r snp_cleaned}
snp = 
  read_csv(
    "data/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```


In the chunk below, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.

```{r unemployment_cleaned}
unemployment = 
  read_csv("data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

In the chunk below, we merge the three datasets.

```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

Let's talk about the 538 datasets. The `pols` data has `r nrow(pols)` observations and `r ncol(pols)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r pols |> pull(year) |> min()` to `r pols |> pull(year) |> max()`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r snp |> pull(year) |> min()` to `r snp |> pull(year) |> max()`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r unemployment |> pull(year) |> min()` to `r unemployment |> pull(year) |> max()`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.


## Problem 2: Mr. Trash Wheel

In the chunk below, we will import the Mr. Trash Wheel dataset, which contains information on the amount and types of litter collected by the Mr. Trash Wheel vessel in Baltimore. 

The homes_powered variable is mutated to reflect on average how many households are powered by the amount of trash collected by Mr. Trash Wheel (in tons). A new variable is created called `tw_type` which distinguishes each named Trash Wheel from the other.

```{r import_MTW}
mtw_data = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", skip = 1,
            sheet = "Mr. Trash Wheel") |> 
  janitor::clean_names() |> 
  filter(row_number() != 585) |> 
  mutate(
    homes_powered = ((weight_tons * 500)/30),
    tw_type = "mtw",
    year = as.numeric(year),
    month = str_to_lower(month)
  ) |> 
  select(-x15, -x16)

view(mtw_data)
```

In the chunk below, we will import, clean, and organize data for Professor Trash Wheel and Gwynnda, two other types of trash wheels that exist in the Baltimore Harbor.

```{r import_ptw_gtw}
ptw_data = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", skip = 1,
            sheet = "Professor Trash Wheel") |> 
  janitor::clean_names() |> 
  filter(row_number() != 107) |> 
  mutate(
    homes_powered = ((weight_tons * 500)/30),
    tw_type = "ptw",
    sports_balls = NA,
    month = str_to_lower(month)
  ) |> 
  select (dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered, tw_type)

gtw_data = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", skip = 1,
            sheet = "Gwynnda Trash Wheel") |> 
  janitor::clean_names() |> 
  filter(!(row_number() %in% c(156,157))) |> 
  mutate(
    homes_powered = ((weight_tons * 500)/30),
    tw_type = "gtw",
    glass_bottles = NA,
    sports_balls = NA,
    month = str_to_lower(month)
  ) |> 
 select (dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered, tw_type)

view(gtw_data)
```


Now we will join all three datasets in the chunk below, creating a combined dataset called `data_tw`.

```{r merge_data}
data_tw = 
 bind_rows(mtw_data,ptw_data,gtw_data) 

```


The `data_tw` data has `r nrow(data_tw)` observations and `r ncol(data_tw)` variables and tells us about the amount (such as weight and volume) and types of litter (such as plastic bottles and cigarette butts) collected by three different trash wheel vessels in the Baltimore Harbor: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel. The data was collected from `r data_tw |> pull(year) |> min()` to `r data_tw |> pull(year) |> max()`. 

The total weight of trash collected by Professor Trash Wheel was `r filter(data_tw, tw_type == "ptw") |> pull(weight_tons) |> sum()` tons.

The total number of cigarette butts collected by Gwynnda in July of 2021 was `r filter(data_tw, tw_type == "gtw", year == 2021, month == "july") |> pull(cigarette_butts) |> sum()`.


##Problem 3: Alzheimer's data

This problem uses data collected from an observational study on the trajectory of Alzheimer's disease (AD) biomarkers. 

In the chunk below we'll import, clean, and tidy the MCI_baseline dataset, which contains information on participant demographics at baseline.

```{r}
mci_baseline = 
  read_csv("data/MCI_baseline.csv", skip=1) |> 
  janitor::clean_names() |>
  filter((current_age < age_at_onset | age_at_onset == ".")) |> 
  mutate(
    sex =
      case_match(
        sex,
        1 ~ "male",
        0 ~ "female"),
    sex = as.factor(sex),
    apoe4 = 
      case_match(
        apoe4,
        1 ~ "carrier",
        0 ~ "noncarrier"),
    apoe4 = as.factor(apoe4)
      )

view(mci_baseline)

```

The MCI study recruited `r nrow(mci_baseline)` participants and collected information on `r ncol(mci_baseline)` variables that tells us about the participants' age, sex, years of education, whether or not they are an APOE4 gene carrier, and age at the onset of MCI if it developed during the follow-up period. 

During the study, `r sum(pull(mci_baseline, age_at_onset) != ".")` participants developed MCI. The average baseline age was `r mean(pull(mci_baseline, current_age)) |> round(2)`. The proportion of women in the study who are apoe4 carriers is `r mci_baseline |> filter(sex == "female", apoe4 == "carrier") |> nrow()/sum(pull(mci_baseline, sex) == "female") * 100`%.


