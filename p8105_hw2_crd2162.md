p8105_hw2_crd2162
================
Caleigh Dwyer
2023-09-26

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

## Problem 1: Cleaning and merging FiveThiryEight data

In the chunk below, we will clean the data in pols-month.csv. This data
comes from 538 and provides information on the number of national
politicians who are democratic or republican at any given time.

There are some values for which `prez_gop` is `2` – these are months in
which Ford became President following Nixon’s resignation. In the new
`president` variable created as part of our data cleaning, we code these
as `gop` (same as values when `prez_gop` is `1`).

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("data/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_num)`

In the chunk below, we will clean the data in snp.csv from 538. This
contains information related to Standard & Poor’s stock market index.

``` r
snp = 
  read_csv(
    "data/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

    ## Joining with `by = join_by(month_num)`

In the chunk below, we tidy the `unemployment` data so that it can be
merged with the `pols` and `snp` datasets.

``` r
unemployment = 
  read_csv("data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_abb)`

In the chunk below, we merge the three datasets.

``` r
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

``` r
str(data_538)
```

    ## tibble [822 × 13] (S3: tbl_df/tbl/data.frame)
    ##  $ year        : num [1:822] 1947 1947 1947 1947 1947 ...
    ##  $ month       : chr [1:822] "January" "February" "March" "April" ...
    ##  $ month_num   : int [1:822] 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ gov_gop     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_gop     : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
    ##  $ rep_gop     : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
    ##  $ gov_dem     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
    ##  $ sen_dem     : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
    ##  $ rep_dem     : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
    ##  $ president   : chr [1:822] "dem" "dem" "dem" "dem" ...
    ##  $ month_abb   : chr [1:822] "Jan" "Feb" "Mar" "Apr" ...
    ##  $ close       : num [1:822] NA NA NA NA NA NA NA NA NA NA ...
    ##  $ unemployment: num [1:822] NA NA NA NA NA NA NA NA NA NA ...

Notice that there are some `NA` values in the `close` and `unemployment`
variables, which indicate that the value of these variables is missing
at those locations.

Let’s talk about the 538 datasets. The `pols` data has 822 observations
and 11 variables and tells us about the party affiliation distribution
(democrat or republican) for governors and senators for a given year
from years 1947 to 2015. It also tells us whether the sitting president
was a democrat or republican. The `snp` data has 787 observations and 3
variables, ranging from years 1950 to 2015. The `unemployment` data has
816 observations and 3 variables ranging from years 1948 to 2015. In
Januarys in or after 1975 in which a democrat was president, the
**average unemployment rate was 6.57**. The average unemployment rate
over the same time period in which a republican was president was 6.47.

## Problem 2: Mr. Trash Wheel

In the chunk below, we will import the Mr. Trash Wheel dataset, which
contains information on the amount and types of litter collected by the
Mr. Trash Wheel vessel in Baltimore.

The homes_powered variable is mutated to reflect on average how many
households are powered by the amount of trash collected by Mr. Trash
Wheel (in tons). A new variable is created called `tw_type` which
distinguishes each named Trash Wheel from the other.

``` r
mtw_data = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", skip = 1,
            sheet = "Mr. Trash Wheel") |> 
  janitor::clean_names() |> 
  filter(row_number() != 585) |> 
  mutate(
    homes_powered = ((weight_tons * 500)/30),
    tw_type = "mtw",
    year = as.numeric(year),
    month = str_to_lower(month)
  ) |> 
  select(-x15, -x16)
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
view(mtw_data)
```

In the chunk below, we will import, clean, and organize data for
Professor Trash Wheel and Gwynnda, two other types of trash wheels that
exist in the Baltimore Harbor.

``` r
ptw_data = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", skip = 1,
            sheet = "Professor Trash Wheel") |> 
  janitor::clean_names() |> 
  filter(row_number() != 107) |> 
  mutate(
    homes_powered = ((weight_tons * 500)/30),
    tw_type = "ptw",
    sports_balls = NA,
    month = str_to_lower(month)
  ) |> 
  select (dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered, tw_type)

gtw_data = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx", skip = 1,
            sheet = "Gwynnda Trash Wheel") |> 
  janitor::clean_names() |> 
  filter(!(row_number() %in% c(156,157))) |> 
  mutate(
    homes_powered = ((weight_tons * 500)/30),
    tw_type = "gtw",
    glass_bottles = NA,
    sports_balls = NA,
    month = str_to_lower(month)
  ) |> 
 select (dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered, tw_type)

view(gtw_data)
```

Now we will join all three datasets in the chunk below, creating a
combined dataset called `data_tw`.

``` r
data_tw = 
 bind_rows(mtw_data,ptw_data,gtw_data) 
```

The `data_tw` data has 845 rows and 15 variables and tells us about the
amount (such as weight and volume) and types of litter (such as plastic
bottles and cigarette butts) collected by three different trash wheel
vessels in the Baltimore Harbor: Mr. Trash Wheel, Professor Trash Wheel,
and Gwynnda Trash Wheel. The data was collected from 2014 to 2023.

The total weight of trash collected by Professor Trash Wheel was 216.26
tons.

The total number of cigarette butts collected by Gwynnda in July of 2021
was 1.63^{4}.

## Problem 3: Alzheimer’s data

This problem uses data collected from an observational study on the
trajectory of Alzheimer’s disease (AD) biomarkers.

In the chunk below we’ll import, clean, and tidy the MCI_baseline
dataset, which contains information on participant demographics at
baseline.

``` r
mci_baseline = 
  read_csv("data/MCI_baseline.csv", skip=1) |> 
  janitor::clean_names() |>
  filter((current_age < age_at_onset | age_at_onset == ".")) |> 
  mutate(
    sex =
      case_match(
        sex,
        1 ~ "male",
        0 ~ "female"),
    sex = as.factor(sex),
    apoe4 = 
      case_match(
        apoe4,
        1 ~ "carrier",
        0 ~ "noncarrier"),
    apoe4 = as.factor(apoe4)
      )
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
view(mci_baseline)
```

The MCI study recruited 479 participants and collected information on 6
variables that tells us about the participants’ age, sex, years of
education, whether or not they are an APOE4 gene carrier, and age at the
onset of MCI if it developed during the follow-up period.

During the study, 93 participants developed MCI. The average baseline
age was 65.03. The proportion of women in the study who are apoe4
carriers is 30%.

In the chunk below, we’ll import and clean the mci_amyloid dataset which
contains information on longitudinally observed biomarker values. The
time (in years) elapsed since the study baseline to the visit where
biomarker Amyloid 42/40 ratio was measured was recorded at five
different time points (baseline, time 2, time 4, time 6, and time 8) for
each participant. The first row was skipped during import as it did not
contain variables or observations. The variable `study_id` was renamed
to match the mci_baseline dataset.

``` r
mci_amyloid = 
  read_csv("data/mci_amyloid.csv", skip=1) |> 
  janitor::clean_names() |> 
  rename(id = study_id)
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
view(mci_amyloid)
```

In the following chunk, we will find any participants who appear in the
baseline data set but not the amyloid data set (and vice versa).

``` r
common_participants =
  inner_join(mci_baseline, mci_amyloid, by = "id")

only_baseline =
  anti_join(mci_baseline, common_participants, by = "id")

only_amyloid =
  anti_join(mci_amyloid, common_participants, by = "id")
```

The following participant IDs appear only in the baseline data and not
in the amyloid data: 14, 49, 92, 179, 268, 304, 389, 412. The following
participant IDs appear only in the amyloid data and not in the baseline
data: 72, 234, 283, 380, 484, 485, 486, 487, 488, 489, 490, 491, 492,
493, 494, 495. In the chunk below, we will use inner join to join the
baseline and amyloid datasets together. Innerjoin removes unmatched
rows.

``` r
mci_combined =
  inner_join(mci_baseline, mci_amyloid, by = "id")
```

The combined dataset has 471 rows and 11 columns.
